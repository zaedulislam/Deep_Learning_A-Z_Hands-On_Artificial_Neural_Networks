{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Building an ANN.ipynb",
      "provenance": [],
      "mount_file_id": "1kbypUiTqCEPr3PZMGXUoq5sbXzZi9UFe",
      "authorship_tag": "ABX9TyO/E7KwGtFEc4SuHmdkA2r4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zaedulislam/Deep_Learning_A-Z_Hands-On_Artificial_Neural_Networks/blob/main/Deep_Learning_A-Z_Hands-On_Artificial_Neural_Networks/Section%204%20-%20Building%20an%20ANN/Building%20an%20ANN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGJJyfp8aOMy"
      },
      "source": [
        "# Artificial Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOUiJWXiaZy6"
      },
      "source": [
        "### Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMA1aVRPfl2Z"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "# TensorFlow is already preinstalled as a library in Google Colab, but we still need to import it\n",
        "import tensorflow as tf"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XwA4TadcEKL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d284b3c4-7c6d-4e2b-dfbd-227b9e125832"
      },
      "source": [
        "# Check the tensorflow version\n",
        "tf.__version__"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.6.0'"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6JCcErYdrVP"
      },
      "source": [
        "# Part 1 - Data Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qaORdo-3eFya"
      },
      "source": [
        "### Importing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APh9A4NEeMT-"
      },
      "source": [
        "dataset = pd.read_csv('/content/Churn_Modelling.csv')\n",
        "# Create matrix of Feature\n",
        "# Take all the columns starting from colum #3(CreditScore) to column #9(EstimatedSalary), finishing 1 before last column\n",
        "X = dataset.iloc[:, 3:-1].values\n",
        "# Take only the last column of the dataset\n",
        "y = dataset.iloc[:, -1].values"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5Znb4sgh6l0",
        "outputId": "4539480c-4dc9-421c-9113-861e78a25ca3"
      },
      "source": [
        "print(X)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[619 'France' 'Female' ... 1 1 101348.88]\n",
            " [608 'Spain' 'Female' ... 0 1 112542.58]\n",
            " [502 'France' 'Female' ... 1 0 113931.57]\n",
            " ...\n",
            " [709 'France' 'Female' ... 0 1 42085.58]\n",
            " [772 'Germany' 'Male' ... 1 0 92888.52]\n",
            " [792 'France' 'Female' ... 1 0 38190.78]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5KDJoO1ah9hc",
        "outputId": "8cc1943a-0b6f-4771-c989-85020fa1dff7"
      },
      "source": [
        "print(y)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 0 1 ... 1 1 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOaTqiRvkqxq"
      },
      "source": [
        "## Encoding categorical data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VU-FYii7kwUN"
      },
      "source": [
        "### Label Encoding the \"Gender\" column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmIunBCRqBXq"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "labelEncoder = LabelEncoder()\n",
        "X[:, 2] = labelEncoder.fit_transform(X[:, 2])"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mRZ284MM9BuV",
        "outputId": "57d3f49d-e8a4-43d8-c8e9-fe3455a8c848"
      },
      "source": [
        "print(X)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[619 'France' 0 ... 1 1 101348.88]\n",
            " [608 'Spain' 0 ... 0 1 112542.58]\n",
            " [502 'France' 0 ... 1 0 113931.57]\n",
            " ...\n",
            " [709 'France' 0 ... 0 1 42085.58]\n",
            " [772 'Germany' 1 ... 1 0 92888.52]\n",
            " [792 'France' 0 ... 1 0 38190.78]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5T21eRQ9SQd"
      },
      "source": [
        "Note: \"Female\" is encoded to \"0\", \"Male\" is to \"1\". That's, of course, a random decision of the machine to choose this Integers, associations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSejR-sHpiOl"
      },
      "source": [
        "### One Hot Encoding the \"Geography\" column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiqknEzkqCIz"
      },
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "columnTransformer = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1])], remainder='passthrough')\n",
        "X = np.array(columnTransformer.fit_transform(X))"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqKFfCvX_yMI",
        "outputId": "49c6ce28-2a3e-4901-ca35-6a23e057d894"
      },
      "source": [
        "print(X)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.0 0.0 0.0 ... 1 1 101348.88]\n",
            " [0.0 0.0 1.0 ... 0 1 112542.58]\n",
            " [1.0 0.0 0.0 ... 1 0 113931.57]\n",
            " ...\n",
            " [1.0 0.0 0.0 ... 0 1 42085.58]\n",
            " [0.0 1.0 0.0 ... 1 0 92888.52]\n",
            " [1.0 0.0 0.0 ... 1 0 38190.78]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dfly0ggd_7FL"
      },
      "source": [
        "Note: When we perform one hot coding while the dummy variables are actually moved to the first columns of the Matrix features in the three first columns.\n",
        "\n",
        "\"1.0 0.0 0.0\", this is the first combination of dummy variables which corresponds to France. Now, Spain was encoded into \"0.0 0.0 1.0\". And finally, Germany was encoded into \"1.0 0.0 0.0\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfaxo92KA9QI"
      },
      "source": [
        "### Splitting the dataset into the Training set and Test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNDe2aRBBDAS"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJwMk44YC2Lb"
      },
      "source": [
        "### Feature Scaling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xkOdzuFC4Pu"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "standardScaler = StandardScaler()\n",
        "X_train = standardScaler.fit_transform(X_train)\n",
        "X_test = standardScaler.transform(X_test)"
      ],
      "execution_count": 34,
      "outputs": []
    }
  ]
}